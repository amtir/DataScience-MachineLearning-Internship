{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88156eb-9911-4b04-bdc4-cdc2a1fab681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMPLE IMPUTER\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "'''scikit-learn (commonly abbreviated as sklearn) is a powerful and widely-used open-source Python library for machine learning.\n",
    "It provides simple, efficient tools for data mining and analysis, and is built on top of other essential libraries like NumPy, SciPy, and Matplotlib.'''\n",
    "\n",
    "# Sample DataFrame with missing values (None)\n",
    "data = {'Age': [25, 30, None, 35, 40, None],\n",
    "        'Salary': [50000, 60000, 65000, None, 70000, 72000]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Method 1: Imputing missing values with the mean\n",
    "# Create an imputer object with the strategy as 'mean'\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "'''SimpleImputer: This is a part of scikit-learn, and it allows you to specify a strategy (like mean, median, most frequent) to fill missing values.\n",
    "Mean Strategy: Replaces missing values with the mean of the column.\n",
    "Median Strategy: Replaces missing values with the median.'''\n",
    "\n",
    "# Fit and transform the data (only the columns with missing values)\n",
    "df[['Age', 'Salary']] = mean_imputer.fit_transform(df[['Age', 'Salary']]) \n",
    "'''Itâ€™s a combination of two actions: fitting a transformation (i.e., calculating the necessary parameters, like mean or scale factor)\n",
    "and applying that transformation to the data in a single step.'''\n",
    "\n",
    "print(\"\\nDataFrame after imputing missing values with mean:\")\n",
    "print(df)\n",
    "\n",
    "# Method 2: Imputing missing values with median (just for example)\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "df[['Age', 'Salary']] = median_imputer.fit_transform(df[['Age', 'Salary']])\n",
    "\n",
    "print(\"\\nDataFrame after imputing missing values with median:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92624d-00cb-4962-b6ec-ee8c027f7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HANDLING CATEGORICAL DATA\n",
    "'''Handling categorical data is a crucial step in machine learning, as most algorithms work with numerical data.\n",
    "There are several techniques to convert categorical data into numerical format, with three popular ones being:\n",
    "\n",
    "get_dummies() (from pandas)\n",
    "LabelEncoder (from sklearn)\n",
    "OneHotEncoder (from sklearn)'''\n",
    "\n",
    "# 1. pandas.get_dummies()\n",
    "'''A function in pandas that converts categorical variable(s) into dummy/indicator variables. \n",
    "Each category becomes a new column with binary values (0 or 1).\n",
    "Best for categorical features that do not have an ordinal relationship (e.g., colors, names).'''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with categorical data\n",
    "data = pd.DataFrame({'Color': ['Red', 'Blue', 'Green']})\n",
    "\n",
    "# Convert the categorical 'Color' column into dummy variables\n",
    "# 'prefix' adds a label to column names to indicate it's related to 'Color'\n",
    "dummies = pd.get_dummies(data['Color'], prefix='Color')\n",
    "print(dummies)\n",
    "\n",
    "# 2. LabelEncoder()\n",
    "'''A class in scikit-learn that converts categorical labels into numeric format by assigning each unique category an integer value.\n",
    "Best for ordinal categorical features where the order matters (e.g., ratings like 'low', 'medium', 'high').'''\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample Data: List of categorical colors\n",
    "data = ['Red', 'Blue', 'Green']\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the data into numeric labels\n",
    "encoded_labels = label_encoder.fit_transform(data)\n",
    "print(encoded_labels)\n",
    "\n",
    "# 3. OneHotEncoder()\n",
    "'''A class in scikit-learn that converts categorical variables into a format that can be provided to ML algorithms to improve predictions.\n",
    "It creates a new binary column for each category.\n",
    "Similar to get_dummies, best for nominal categorical features without ordinal relationships.'''\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sample Data: A list of lists (each inner list is a sample)\n",
    "data = [['Red'], ['Blue'], ['Green']]\n",
    "\n",
    "# Create an instance of OneHotEncoder with sparse_output set to False to get a dense array\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform the data into one-hot encoded format\n",
    "one_hot_encoded = encoder.fit_transform(data)\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f506a97-82cd-4972-8ff1-8a52a0060b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING DATA (TRAIN/TEST SPLIT)\n",
    "'''A train/test split is a common technique in machine learning used to evaluate the performance of a model. The dataset is divided into two parts:\n",
    "\n",
    "Training set: Used to train the model. The model learns patterns and relationships from this subset of data.\n",
    "Testing set: Used to evaluate how well the trained model performs on unseen data. This helps assess its generalization capability.\n",
    "\n",
    "The typical ratio for splitting data is:\n",
    "\n",
    "80% training and 20% testing, \n",
    "or\n",
    "70% training and 30% testing.'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Example feature data (X) and target data (y)\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14], [15, 16]])\n",
    "y = np.array([0, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "'''test_size=0.2: 20% of the data will be held out for testing.\n",
    "random_state=42: Ensures the split is reproducible.'''\n",
    "\n",
    "# Print the results\n",
    "print(\"X_train:\", X_train)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"y_test:\", y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
